---
layout:     post
title:      "Color Block Tracking and Pose Prediction"
subtitle:   "ROS + openCV + Kalman Filter"
author:     "bythew3i"
header-img: "img/post/20191006/bg.png"
tags:
    - ROS
    - Computer Vison
    - Kalman Filter
    - openCV
    - robot
---

> In this project, I learned about the popular colorspaces used in Computer Vison and successfully implemented the Kalman Filter Algorithm to predict the movement of object (Pose Prediction).

### Environment
- Ubuntu 18.04
- [ROS Melodic](http://wiki.ros.org/melodic/Installation/Ubuntu)
- RealSense D435 camera

### Requirement
- [RealSense driver](https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md)
- [realsense2_camera ROS package](https://github.com/IntelRealSense/realsense-ros)


### Detecting a Visual Target
First, my main ideas of detecting the color block were coming from these posts:
- [Tutorial on Color Spaces in OpenCV](https://www.learnopencv.com/color-spaces-in-opencv-cpp-python/)
- [Color Filtering OpenCV Python Tutorial](https://pythonprogramming.net/color-filter-python-opencv-tutorial/)
- [Tutorial on Blob Detection](https://www.learnopencv.com/blob-detection-using-opencv-python-c/)

The `input bag` (video resource) was provided by professor [Marynel V√ÅZQUEZ](http://www.marynel.net/)

![input](/img/post/20191006/in.gif)

After `color filtering`, I was able to capture the movement of the blue block.

![cl](/img/post/20191006/cl.gif)




### Kalman Filter: Pose Prediction

The `filter state` $`\bold{x} \in \mathbb{R}^6`$ should contain $`\bold{x} = [p_x\ p_y\ v_x\ v_y\ a_x\ a_y]^T`$, where $`\mathbf{p} = [p_x\ p_y]^T`$ corresponds to the estimated position of the target in an image, $`\mathbf{v} = [v_x\ v_y]^T`$ is its estimated velocity, and $`\mathbf{a} = [a_x\ a_y]^T`$ is its estimated acceleration.

The `transition model` of the filter should include additive gaussian noise and  follow the [equations of motion](https://en.wikipedia.org/wiki/Equations_of_motion):

- $`\bold{p}_{t+1} = \bold{p}_t + \bold{v}_t \Delta t + \frac{1}{2} \bold{a} (\Delta t)^2`$
- $`\bold{v}_{t+1} = \bold{v}_t + \bold{a}_t \Delta t`$
- $`\bold{a}_{t+1} = \bold{a}_t`$

where $`\Delta t`$ is the elapsed time between updates.

The `measurement model` of the filter should correct for the predicted state based on the observed position of the visual target. This observation is generated by your detect_visual_target.py
node.

<img src="/img/post/20191006/KFA.jpeg">

After applying Kalman Filter Algorithm, I got this output:

![kf](/img/post/20191006/kf.gif)

> The images sent over the /tracked_image topic display two trajectories: the `red line` connects the observed locations for the target (as received through the /observations topic); and the `thinner green line` connects the estimated location for the target (from the Kalman Filter belief).


### Real-Time Filtering
Based on the ROS and RealSense D435 camera, I implemented a Yellow block tracking (`red line`) and Kalman Filter Pose prediction (`green line`) in real time system.

<iframe src="https://www.youtube.com/embed/qhstN7fMYwk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
